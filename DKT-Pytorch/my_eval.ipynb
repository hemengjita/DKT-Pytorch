{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handle import DatasetHandler\n",
    "from model_handle import ModelHandler\n",
    "\n",
    "#train_data_path = '../data/kddcup2010_train.txt'\n",
    "test_data_path = '../data/kddcup2010_test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- batch : batch(user) by 49+1(excercise, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data:    : 538it [00:00, 1396.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "---------- cuda:0 ----------\n",
      "------------------------------\n",
      "compile model --------------------\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "lossFunc(\n",
      "  (loss_fn): BCELoss()\n",
      ")\n",
      "\n",
      "DKT(\n",
      "  (lstm): LSTM(1322, 200, batch_first=True)\n",
      "  (fc): Linear(in_features=200, out_features=661, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from constants import *\n",
    "\n",
    "data_handler = DatasetHandler()\n",
    "#train_generator = data_handler.get_data_generator(train_data_path)\n",
    "val_generator = data_handler.get_data_generator(test_data_path)\n",
    "\n",
    "model_handler = ModelHandler(input_dim, hidden_dim, num_layers, output_dim)\n",
    "model_handler.load_model('/home/fanzhilin/code/konwledge_tracing/1-py_dkt-master/outputs/20_0.3381_0.7372.pth')\n",
    "model_handler.compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_handler.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 1322])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test sample \n",
    "batch_sample = next(iter(val_generator))\n",
    "batch_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "rand_idx = random.randint(0, batch_sample.shape[0] - 1)\n",
    "rand_idx#随机取一个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1322])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = batch_sample[rand_idx]\n",
    "x.shape#取出一个样本，代表一个学生的做题记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_sequence tensor([570., 274., 124., 105., 323.,  71., 533., 522., 145., 573., 123.,  77.,\n",
      "        281., 195., 422., 589., 536., 312., 556., 330., 283., 169., 507., 537.,\n",
      "        370., 125., 107., 170.,  21.,  18., 224., 355., 658., 275., 429., 500.,\n",
      "        591., 115., 647., 464., 173.,  83., 298., 314.,  49., 103., 622., 443.,\n",
      "        567., 223.])\n",
      "a_sequence tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "       device='cuda:0')\n",
      "--------------------------------------------------\n",
      "sol excercise tags: \n",
      " tensor([570., 274., 124., 105., 323.,  71., 533., 522., 145., 573., 123.,  77.,\n",
      "        281., 195., 422., 589., 536., 312., 556., 330., 283., 169., 507., 537.,\n",
      "        370., 125., 107., 170.,  21.,  18., 224., 355., 658., 275., 429., 500.,\n",
      "        591., 115., 647., 464., 173.,  83., 298., 314.,  49., 103., 622., 443.])\n",
      "result excercise tags: \n",
      " tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0')\n",
      "--------------------------------------------------\n",
      "predict excercise tag 223.0\n",
      "ground truth : 1.0\n",
      "this student has a 93.85% chance of solving this problem\n"
     ]
    }
   ],
   "source": [
    "model_handler.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_sequence tensor([468., 332., 468., 332.,  40., 438.,  75., 421., 380., 421.,  -1.,  -1.,\n",
      "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
      "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
      "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
      "         -1.,  -1.])\n",
      "a_sequence tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "--------------------------------------------------\n",
      "sol excercise tags: \n",
      " tensor([468., 332., 468., 332.,  40., 438.,  75., 421.])\n",
      "result excercise tags: \n",
      " tensor([1., 0., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "--------------------------------------------------\n",
      "predict excercise tag 421.0\n",
      "ground truth : 1.0\n",
      "this student has a 97.65% chance of solving this problem\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "rand_idx = random.randint(0, batch_sample.shape[0] - 1)\n",
    "x = batch_sample[rand_idx]\n",
    "prob = model_handler.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1322])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape#从batch中取出一个样本，代表一个学生的做题记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DKT(\n",
       "  (lstm): LSTM(1322, 200, batch_first=True)\n",
       "  (fc): Linear(in_features=200, out_features=661, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_handler.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得模型预测的概率，即学生下一次做对的概率\n",
    "def _cal_prob(x,model):#x=[1, seq_len, numofq*2]\n",
    "\n",
    "    # qt\n",
    "    delta = x[:,:,:QUESTION_NUM] + x[:,:,QUESTION_NUM:]\n",
    "\n",
    "    # qt+1\n",
    "    delta = delta[:,1:,:].permute(0,2,1)\n",
    "\n",
    "    # yt\n",
    "    pred = model(x)\n",
    "    y = pred[:, :MAX_SEQ - 1,:]\n",
    "\n",
    "    # pred at+1\n",
    "    temp = torch.matmul(y, delta) # 1, MAX_SEQ, MAX_SEQ-1(prob)\n",
    "\n",
    "    # get excercise prob from diagonal matrix\n",
    "    prob = torch.diagonal(temp, dim1=1, dim2=2) # 1, MAX_SEQ-1(prob)\\\n",
    "\n",
    "    return prob.squeeze(0)#再把batch维度去掉 1, MAX_SEQ-1(prob) -> MAX_SEQ-1(prob) 每一个值代表预测该问题上学生作答正确的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 468],\n",
       "        [  1, 993],\n",
       "        [  2, 468],\n",
       "        [  3, 332],\n",
       "        [  4,  40],\n",
       "        [  5, 438],\n",
       "        [  6,  75],\n",
       "        [  7, 421],\n",
       "        [  8, 380],\n",
       "        [  9, 421]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.nonzero()#x只有46个非零元素1，代表学生做了46道题，因为要跳过第一个时间步，所以只有45道题，为什么要跳过第一个时间步？因为第一个时间步的数据是用来预测第二个时间步的数据，所以要跳过第一个时间步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 1322])\n",
      "torch.Size([49])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "torch.Size([50])\n",
      "--------------------------------------------------\n",
      "单个学生有效作答sol excercise tags: \n",
      " tensor([468., 332., 468., 332.,  40., 438.,  75., 421., 380.])\n",
      "对应的原始结果result excercise tags: \n",
      " tensor([1., 0., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "--------------------------------------------------\n",
      "predict excercise tag 421.0\n",
      "ground truth : 1.0\n",
      "this student has a 97.65% chance of solving this problem\n",
      "--------------------------------------------------\n",
      "predict prob tensor([0.9643, 0.9357, 0.9774, 0.9996, 0.1447, 0.9999, 0.9584, 0.9573, 0.9765,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 一条预测的序列\n",
    "import torch\n",
    "if len(x.size()) == 2:#先给x增加一个维度，因为要送入模型·\n",
    "    x = x.unsqueeze(0)\n",
    "print(x.shape)#x的维度是(1, MAX_SEQ, numofq*2)\n",
    "\n",
    "x = x.to(model_handler.model.device)\n",
    "\n",
    "prob = _cal_prob(x, model_handler.model)\n",
    "print(prob.shape)#prob的维度是(MAX_SEQ-1,)\n",
    "\n",
    "q_sequence = _get_q_sequence(x)\n",
    "print(q_sequence.shape)#q_sequence的维度是(MAX_SEQ,)\n",
    "\n",
    "a_sequence = _get_a_sequence(x)\n",
    "print(a_sequence.shape)#a_sequence的维度是(MAX_SEQ,)\n",
    "\n",
    "if -1 in q_sequence:#如果有-1，说明这个step学生的作答是填充了的\n",
    "    last_excercise_tag = torch.nonzero(q_sequence == -1)[0][0].item() - 1 #torch.nonzero(q_sequence == -1)寻找-1的位置\n",
    "else:#如果没有-1\n",
    "    last_excercise_tag = len(q_sequence) - 1#为什么要-1？？\n",
    "\n",
    "\n",
    "# print(\"q_sequence\",q_sequence)\n",
    "# print(\"a_sequence\",a_sequence)\n",
    "\n",
    "\n",
    "print('-' * 50)\n",
    "print(f'单个学生有效作答sol excercise tags: \\n {q_sequence[:last_excercise_tag]}')\n",
    "print(f'对应的原始结果result excercise tags: \\n {a_sequence[:last_excercise_tag]}')\n",
    "print('-' * 50)\n",
    "\n",
    "print(f'predict excercise tag {q_sequence[last_excercise_tag]}')\n",
    "print(f'ground truth : {a_sequence[last_excercise_tag]}')\n",
    "print(f'this student has a {prob[last_excercise_tag-1]*100:.2f}% chance of solving this problem')\n",
    "print('-' * 50)\n",
    "print(f'predict prob {prob}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9643, 0.9357, 0.9774, 0.9996, 0.1447, 0.9999, 0.9584, 0.9573, 0.9765,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob#只有45个值，因为用户只做了45道题（跳过第一个时间步）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里目前有单看不太懂!\n",
    "def _get_q_sequence(q_seq_one_hot):#q_seq_one_hot=[1, seq_len, numofq*2]\n",
    "\n",
    "    q_sequence = []\n",
    "    one_hot_excercise_tags = q_seq_one_hot[:, :, :QUESTION_NUM] + q_seq_one_hot[:, :, QUESTION_NUM:]#q_seq_one_hot=[1, seq_len, numofq]学生做题标记，无论正错都是1\n",
    "    one_hot_excercise_tags = one_hot_excercise_tags.squeeze(0)#去掉batch维度 形状变为(seq_len, numofq)\n",
    "    \n",
    "    for one_hot_excercise_tag in one_hot_excercise_tags:#对每一个step处理\n",
    "        \n",
    "        try:#找到用户作答最后一次的位置\n",
    "            excercise_tag = torch.nonzero(one_hot_excercise_tag).item()#找到学生作答的位置索引，其实就是题目编号\n",
    "        except:\n",
    "            excercise_tag = -1 #如果找不到作答记录，说明学生在这个step时间上没有作答，标记为-1\n",
    "\n",
    "        q_sequence.append(excercise_tag)#学生原始的做题记录，保证是maxstep长度，如果没有做题，标记为-1\n",
    "\n",
    "    return torch.Tensor(q_sequence)#list返回tensor类型，方便操作\n",
    "\n",
    "def _get_a_sequence(q_seq_one_hot):#q_seq_one_hot=[1, seq_len, numofq*2]\n",
    "    q_seq_one_hot = q_seq_one_hot.squeeze(0)#去掉batch维度 形状变为(seq_len, numofq*2)\n",
    "    a_sequence = ((q_seq_one_hot[:, :QUESTION_NUM] - q_seq_one_hot[:, QUESTION_NUM:]).sum(1) + 1) // 2 #拿到原始学生作答对应的正误记录\n",
    "    return a_sequence#对于没有作答的step，标记为0 ，而不是-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_seq_one_hot=x\n",
    "q_sequence = []\n",
    "one_hot_excercise_tags = q_seq_one_hot[:, :, :QUESTION_NUM] + q_seq_one_hot[:, :, QUESTION_NUM:]#q_seq_one_hot=[1, seq_len, numofq]学生做题标记，无论正错都是1\n",
    "one_hot_excercise_tags = one_hot_excercise_tags.squeeze(0)#去掉batch维度 形状变为(seq_len, numofq)\n",
    "one_hot_excercise_tags.shape\n",
    "one_hot_excercise_tags.sum(1)#每一行的和都是1，但学生只做了46道题，所以只有46个1，其他都是0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_sequence = _get_q_sequence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([468., 332., 468., 332.,  40., 438.,  75., 421., 380., 421.,  -1.,  -1.,\n",
       "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
       "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
       "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
       "         -1.,  -1.])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sequence == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if -1 in q_sequence:#如果有-1，说明这个step学生的作答是填充了的,\n",
    "    last_excercise_tag = torch.nonzero(q_sequence == -1)[0][0].item() - 1 #torch.nonzero(q_sequence == -1)寻找-1的位置，[0][0].item()取第一次出现的位置\n",
    "else:#如果没有-1\n",
    "    last_excercise_tag = len(q_sequence) - 1\n",
    "last_excercise_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, tensor(421.))"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(q_sequence == -1)[0][0].item(),q_sequence[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([468., 332., 468., 332.,  40., 438.,  75., 421., 380., 421.,  -1.,  -1.,\n",
       "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
       "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
       "         -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,\n",
       "         -1.,  -1.])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([468., 332., 468., 332.,  40., 438.,  75., 421.])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用户当前作答\n",
    "q_sequence[:last_excercise_tag-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(421.)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#需要预测的问题id 为什么不是380？\n",
    "q_sequence[last_excercise_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sequence[torch.nonzero(q_sequence == -1)[0][0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "if -1 in q_sequence:#如果有-1，说明这个step学生的作答是填充了的,\n",
    "    last_excercise_tag = torch.nonzero(q_sequence == -1)[0][0].item() - 1 #torch.nonzero(q_sequence == -1)寻找-1的位置，[0][0].item()取第一次出现的位置\n",
    "else:#如果没有-1\n",
    "    last_excercise_tag = len(q_sequence) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "468\n"
     ]
    }
   ],
   "source": [
    "for one_hot_excercise_tag in one_hot_excercise_tags:#对每一个step的one_hot_excercise_tag进行处理\n",
    "    print(one_hot_excercise_tag)\n",
    "    print(torch.nonzero(one_hot_excercise_tag).item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[247], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     excercise_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mq_sequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(excercise_tag)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for one_hot_excercise_tag in one_hot_excercise_tags:\n",
    "    try:\n",
    "        excercise_tag = torch.nonzero(one_hot_excercise_tag).item()\n",
    "    except:\n",
    "        excercise_tag = -1\n",
    "\n",
    "    q_sequence.append(excercise_tag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
